import tensorflow as tf
import os
import matplotlib.pyplot as plt

dataset_path = '/content/drive/MyDrive/dataset-resized' #replace with your file
os.listdir(dataset_path)

train_data = tf.keras.preprocessing.image_dataset_from_directory(
    dataset_path,
    validation_split=0.2,
    subset="training",
    seed=123,
    image_size=(224, 224),
    batch_size=32
)

val_data = tf.keras.preprocessing.image_dataset_from_directory(
    dataset_path,
    validation_split=0.2,
    subset="validation",
    seed=123,
    image_size=(224, 224),
    batch_size=32,
)

def encode_labels(dataset):
    return dataset.map(lambda x, y: (x, tf.one_hot(y, depth=7)))

train_data = encode_labels(train_data)
val_data = encode_labels(val_data)

img_size = (224, 224)


# Load the pre-trained MobileNetV2 model without the top layers
base_model = tf.keras.applications.MobileNetV2(
    input_shape=(img_size[0], img_size[1], 3),
    include_top=False,  # Remove fully connected layers
    weights='imagenet'
)
base_model.trainable = False

# Build the model
model = tf.keras.Sequential([
    base_model,
    tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(7, activation='softmax')  # Update for your number of classes
])

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])



early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
# Train the model
history = model.fit(train_data, validation_data=val_data, epochs=15)

# Get the final accuracy
train_acc = history.history['accuracy'][-1]
val_acc = history.history['val_accuracy'][-1]

print(f"Final Training Accuracy: {train_acc:.4f}")
print(f"Final Validation Accuracy: {val_acc:.4f}")


# For the Graphs
# Extract loss values from training history
loss = history.history['loss']  # Training loss
val_loss = history.history['val_loss']  # Validation loss
epochs = range(1, len(loss) + 1)  # X-axis: Epochs

# Create the loss graph
plt.figure(figsize=(8, 6))
plt.plot(epochs, loss, 'b', label='Training Loss')  # Blue for training loss
plt.plot(epochs, val_loss, 'r', label='Validation Loss')  # Red for validation loss

# Labels and Title
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training vs. Validation Loss')
plt.legend()

# Show the graph
plt.show()

